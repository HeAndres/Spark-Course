{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master('local').appName('friends').getOrCreate()\n",
    "\n",
    "lines = spark.sparkContext.textFile('fakefriends.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0,Will,33,385',\n",
       " '1,Jean-Luc,26,2',\n",
       " '2,Hugh,55,221',\n",
       " '3,Deanna,40,465',\n",
       " '4,Quark,68,21']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame, Row\n",
    "def process_line(line):\n",
    "    \n",
    "    line = line.split(',')\n",
    "    \n",
    "    line = Row(ID = int(line[0]), name = line[1],\n",
    "               age = int(line[2]), n_friends = int(line[3]))\n",
    "    \n",
    "    return line\n",
    "\n",
    "rdd = lines.map(process_line)\n",
    "schemaPeople = spark.createDataFrame(rdd).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|    name|count|\n",
      "+--------+-----+\n",
      "|    Data|   25|\n",
      "| Beverly|   20|\n",
      "|    Hugh|   20|\n",
      "|   Dukat|   21|\n",
      "|Jean-Luc|   16|\n",
      "|     Nog|   22|\n",
      "|     Odo|   15|\n",
      "|  Kasidy|   19|\n",
      "|  Guinan|   12|\n",
      "|   Leeta|   15|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemaPeople.groupBy('name').count().limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|    name|count(1)|\n",
      "+--------+--------+\n",
      "|    Data|      25|\n",
      "| Beverly|      20|\n",
      "|    Hugh|      20|\n",
      "|   Dukat|      21|\n",
      "|Jean-Luc|      16|\n",
      "|     Nog|      22|\n",
      "|     Odo|      15|\n",
      "|  Kasidy|      19|\n",
      "|  Guinan|      12|\n",
      "|   Leeta|      15|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemaPeople.createOrReplaceTempView('people')\n",
    "spark.sql('SELECT name, COUNT(*) FROM people GROUP BY name LIMIT 10').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+---------+\n",
      "| ID|    name|age|n_friends|\n",
      "+---+--------+---+---------+\n",
      "|  0|    Will| 33|      385|\n",
      "|  1|Jean-Luc| 26|        2|\n",
      "|  2|    Hugh| 55|      221|\n",
      "|  3|  Deanna| 40|      465|\n",
      "|  4|   Quark| 68|       21|\n",
      "+---+--------+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master('local').appName('friends').getOrCreate()\n",
    "\n",
    "lines = spark.sparkContext.textFile('fakefriends.csv')\n",
    "rdd = (\n",
    "    lines\n",
    "    .map(lambda x: x.split(',')) \\\n",
    "    .map(lambda x: Row(ID = int(x[0]), name = x[1], age = int(x[2]), n_friends = int(x[3])))\n",
    ")\n",
    "# [Row(ID=0, name='Will', age=33, n_friends=385),\n",
    "#  Row(ID=1, name='Jean-Luc', age=26, n_friends=2),\n",
    "#  Row(ID=2, name='Hugh', age=55, n_friends=221)]\n",
    "\n",
    "schemaPeople = spark.createDataFrame(rdd).cache()\n",
    "# schemaPeople.limit(5).show()\n",
    "# +---+--------+---+---------+\n",
    "# | ID|    name|age|n_friends|\n",
    "# +---+--------+---+---------+\n",
    "# |  0|    Will| 33|      385|\n",
    "# |  1|Jean-Luc| 26|        2|\n",
    "# |  2|    Hugh| 55|      221|\n",
    "# |  3|  Deanna| 40|      465|\n",
    "# |  4|   Quark| 68|       21|\n",
    "\n",
    "schemaPeople.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "|age|total_friends|\n",
      "+---+-------------+\n",
      "| 18|          343|\n",
      "| 19|          213|\n",
      "| 20|          165|\n",
      "| 21|          351|\n",
      "| 22|          206|\n",
      "| 23|          246|\n",
      "| 24|          234|\n",
      "| 25|          197|\n",
      "| 26|          242|\n",
      "| 27|          228|\n",
      "+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemaPeople.createOrReplaceTempView('people')\n",
    "spark.sql('SELECT age, CAST(ROUND(AVG(n_friends)) AS INT) AS total_friends FROM people GROUP BY age ORDER BY age LIMIT 10').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+\n",
      "|age|sum(n_friends)|\n",
      "+---+--------------+\n",
      "| 26|          4115|\n",
      "| 29|          2591|\n",
      "| 65|          1491|\n",
      "| 54|          3615|\n",
      "| 19|          2346|\n",
      "| 22|          1445|\n",
      "| 34|          1473|\n",
      "| 50|          1273|\n",
      "| 57|          3106|\n",
      "| 43|          1614|\n",
      "| 32|          2287|\n",
      "| 31|          2138|\n",
      "| 39|          1185|\n",
      "| 25|          2172|\n",
      "| 68|          2696|\n",
      "| 58|          1282|\n",
      "| 27|          1825|\n",
      "| 63|          1536|\n",
      "| 56|          1840|\n",
      "| 51|          2115|\n",
      "+---+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemaPeople.groupby('age').sum('n_friends').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
