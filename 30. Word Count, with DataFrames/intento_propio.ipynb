{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/10 15:22:05 WARN Utils: Your hostname, AHE resolves to a loopback address: 127.0.1.1; using 192.168.121.8 instead (on interface wlo1)\n",
      "23/10/10 15:22:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/10 15:22:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master('local').appName('wordCount').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                line|\n",
      "+--------------------+\n",
      "|Self-Employment: ...|\n",
      "|Achieving Financi...|\n",
      "|       By Frank Kane|\n",
      "|Copyright � 2015 ...|\n",
      "+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book = spark.read.option('header', 'false').csv('Book').withColumnRenamed('_c0', 'line')\n",
    "book.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                line|\n",
      "+--------------------+\n",
      "|Self-Employment: ...|\n",
      "|Achieving Financi...|\n",
      "|       By Frank Kane|\n",
      "|Copyright � 2015 ...|\n",
      "+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|     words|\n",
      "+----------+\n",
      "|      Self|\n",
      "|Employment|\n",
      "|  Building|\n",
      "|        an|\n",
      "|  Internet|\n",
      "|  Business|\n",
      "|        of|\n",
      "|       One|\n",
      "| Achieving|\n",
      "| Financial|\n",
      "|       and|\n",
      "|  Personal|\n",
      "|   Freedom|\n",
      "|   through|\n",
      "|         a|\n",
      "| Lifestyle|\n",
      "|Technology|\n",
      "|  Business|\n",
      "|        By|\n",
      "|     Frank|\n",
      "|      Kane|\n",
      "| Copyright|\n",
      "|      2015|\n",
      "|     Frank|\n",
      "|      Kane|\n",
      "|          |\n",
      "|       All|\n",
      "|    rights|\n",
      "|  reserved|\n",
      "| worldwide|\n",
      "+----------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as func\n",
    "\n",
    "words = book.select(\n",
    "    func.explode(\n",
    "        func.split(\n",
    "            book.line,\n",
    "            '\\\\W+'\n",
    "            )\n",
    "    ).alias('words')\n",
    "    )\n",
    "words.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|     words|\n",
      "+----------+\n",
      "|     Email|\n",
      "|    matter|\n",
      "|      many|\n",
      "|      make|\n",
      "|ultimately|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "words.filter(col('words').contains('ma')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| you|  406|\n",
      "|your|  373|\n",
      "|  to|  345|\n",
      "| the|  282|\n",
      "|   a|  265|\n",
      "+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = book.select(\n",
    "    func.explode(\n",
    "        func.split(\n",
    "            func.lower(book.line),\n",
    "            '\\\\W+'\n",
    "        )\n",
    "    ).alias('word')\n",
    ")\n",
    "\n",
    "words.groupby('word').count().sort('count', ascending = False).show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
