{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master('local').appName('minTemp').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('stationID', StringType(), True),\n",
    "    StructField('date', IntegerType(), True),\n",
    "    StructField('measure_type', StringType(), True),\n",
    "    StructField('temperature', FloatType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------------+-----------+\n",
      "|  stationID|    date|measure_type|temperature|\n",
      "+-----------+--------+------------+-----------+\n",
      "|ITE00100554|18000101|        TMAX|      -75.0|\n",
      "|ITE00100554|18000101|        TMIN|     -148.0|\n",
      "|GM000010962|18000101|        PRCP|        0.0|\n",
      "|EZE00100082|18000101|        TMAX|      -86.0|\n",
      "+-----------+--------+------------+-----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.schema(schema).csv('1800.csv')\n",
    "df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+\n",
      "|  stationID|min(temperature)|\n",
      "+-----------+----------------+\n",
      "|ITE00100554|          -148.0|\n",
      "|EZE00100082|          -135.0|\n",
      "+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from pyspark.sql.functions import col\n",
    "\n",
    "# Min temperature by station\n",
    "(\n",
    "    df\n",
    "    .filter('measure_type == \"TMIN\"')\n",
    "    .groupby('stationID')\n",
    "    .min('temperature')\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------------+-----------+\n",
      "|  stationID|    date|measure_type|temperature|\n",
      "+-----------+--------+------------+-----------+\n",
      "|ITE00100554|18000101|        TMAX|      -75.0|\n",
      "|ITE00100554|18000101|        TMIN|     -148.0|\n",
      "|GM000010962|18000101|        PRCP|        0.0|\n",
      "|EZE00100082|18000101|        TMAX|      -86.0|\n",
      "+-----------+--------+------------+-----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.withColumn(\n",
    "    'temperature',\n",
    "    col('temperature')\n",
    ").show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    date|\n",
      "+--------+\n",
      "|18000101|\n",
      "|18000102|\n",
      "|18000103|\n",
      "|18000104|\n",
      "|18000105|\n",
      "|18000106|\n",
      "|18000107|\n",
      "|18000108|\n",
      "|18000109|\n",
      "|18000110|\n",
      "|18000111|\n",
      "|18000112|\n",
      "|18000113|\n",
      "|18000114|\n",
      "|18000115|\n",
      "|18000116|\n",
      "|18000117|\n",
      "|18000118|\n",
      "|18000119|\n",
      "|18000120|\n",
      "|18000121|\n",
      "|18000122|\n",
      "|18000123|\n",
      "|18000124|\n",
      "|18000125|\n",
      "|18000126|\n",
      "|18000127|\n",
      "|18000128|\n",
      "|18000129|\n",
      "|18000130|\n",
      "|18000131|\n",
      "|18000201|\n",
      "|18000202|\n",
      "|18000203|\n",
      "|18000204|\n",
      "|18000205|\n",
      "|18000206|\n",
      "|18000207|\n",
      "|18000208|\n",
      "|18000209|\n",
      "|18000210|\n",
      "|18000211|\n",
      "|18000212|\n",
      "|18000213|\n",
      "|18000214|\n",
      "|18000215|\n",
      "|18000216|\n",
      "|18000217|\n",
      "|18000218|\n",
      "|18000219|\n",
      "|18000220|\n",
      "|18000221|\n",
      "|18000222|\n",
      "|18000223|\n",
      "|18000224|\n",
      "|18000225|\n",
      "|18000226|\n",
      "|18000227|\n",
      "|18000228|\n",
      "|18000301|\n",
      "|18000302|\n",
      "|18000303|\n",
      "|18000304|\n",
      "|18000305|\n",
      "|18000306|\n",
      "|18000307|\n",
      "|18000308|\n",
      "|18000309|\n",
      "|18000310|\n",
      "|18000311|\n",
      "|18000312|\n",
      "|18000313|\n",
      "|18000314|\n",
      "|18000315|\n",
      "|18000316|\n",
      "|18000317|\n",
      "|18000318|\n",
      "|18000319|\n",
      "|18000320|\n",
      "|18000321|\n",
      "|18000322|\n",
      "|18000323|\n",
      "|18000324|\n",
      "|18000325|\n",
      "|18000326|\n",
      "|18000327|\n",
      "|18000328|\n",
      "|18000329|\n",
      "|18000330|\n",
      "|18000331|\n",
      "|18000401|\n",
      "|18000402|\n",
      "|18000403|\n",
      "|18000404|\n",
      "|18000405|\n",
      "|18000406|\n",
      "|18000407|\n",
      "|18000408|\n",
      "|18000409|\n",
      "|18000410|\n",
      "|18000411|\n",
      "|18000412|\n",
      "|18000413|\n",
      "|18000414|\n",
      "|18000415|\n",
      "|18000416|\n",
      "|18000417|\n",
      "|18000418|\n",
      "|18000419|\n",
      "|18000420|\n",
      "|18000421|\n",
      "|18000422|\n",
      "|18000423|\n",
      "|18000424|\n",
      "|18000425|\n",
      "|18000426|\n",
      "|18000427|\n",
      "|18000428|\n",
      "|18000429|\n",
      "|18000430|\n",
      "|18000501|\n",
      "|18000502|\n",
      "|18000503|\n",
      "|18000504|\n",
      "|18000505|\n",
      "|18000506|\n",
      "|18000507|\n",
      "|18000508|\n",
      "|18000509|\n",
      "|18000510|\n",
      "|18000511|\n",
      "|18000512|\n",
      "|18000513|\n",
      "|18000514|\n",
      "|18000515|\n",
      "|18000516|\n",
      "|18000517|\n",
      "|18000518|\n",
      "|18000519|\n",
      "|18000520|\n",
      "|18000521|\n",
      "|18000522|\n",
      "|18000523|\n",
      "|18000524|\n",
      "|18000525|\n",
      "|18000526|\n",
      "|18000527|\n",
      "|18000528|\n",
      "|18000529|\n",
      "|18000530|\n",
      "+--------+\n",
      "only showing top 150 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.stationID == 'ITE00100554').select('date').distinct().sort('date').show(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|    a|\n",
      "+-----+\n",
      "|false|\n",
      "| true|\n",
      "|false|\n",
      "|false|\n",
      "+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select((df.measure_type == 'TMIN').alias('a')) \\\n",
    "    .show(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
